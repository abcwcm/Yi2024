---
title: "MNN"
subtitle: "For datasets that are not TISCH annotated "
date: "`r Sys.Date()`"
output:
    html_document:
        toc: true
        code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE, cache.lazy = FALSE, warning=FALSE, message=FALSE)
```

```{r libraries, chache=FALSE}
library(data.table)
library(magrittr)
library(kableExtra)
library(ggplot2); theme_set(theme_bw())
library(patchwork)
library(SingleCellExperiment)
library(DropletUtils)
library(scater)
library(scran)
library(magrittr)
library(batchelor)
options(scipen=1000000)
data_dir <- "/Users/pz/Desktop/work/chris-klebanoff_fei/analysis/datasets"
```


Let's re-work the folliwng two datasets:

**NSCLC_GSE176021**: not part of TISCH and so not annotated.

**KIRC_GSE111360**: PBMC sample is not part of TISCH annotation.

First, let's filter same way TSICH did:

min.cells = 10
min.features = 500

Then, run singleR.


```{r local_data_load, eval=TRUE}
min.cells = 10
min.features = 500

files <- list.files(path=".", pattern  = "sce_unfiltered_*",full.names = TRUE)
files = grep("NSCLC_GSE176021|KIRC_GSE111360", files, value=T)

scel <- lapply(files, function(x){ 
 sce = readRDS(x)
  # Filter based on min.features
  nfeatures <- Matrix::colSums(x = counts(sce) > 0)
  sce <- sce[, which(x = nfeatures >= min.features)]
  
  # filter genes on the number of cells expressing
  num.cells <- Matrix::rowSums(x = counts(sce) > 0)
  sce[which(x = num.cells >= min.cells),]
}) 

names(scel) = gsub(".*/","",files) %>% gsub("sce_unfiltered_","",.) %>% gsub("_2022-07-22.rds","",.)
```


```{r,  eval=TRUE}
#' Extract a subset of cells from a composite SCE file
#' 
#' @details The only point of this function is to harmonize the 
#' resulting SCE files to enable the generation of a list of SCEs
#' that are ready for MNN-integration, i.e. they have counts() etc.
#' @param insce SCE object
#' @return SCE object
#' @examples
#' scel <- lapply(unique(sce$Sample), function(x) individualize_samples(sce[, sce$Sample == x]))
#' names(scel) <- unique(sce$Sample)
individualize_samples <- function(insce, pf = "old",
    shared_colData = c("cell","Sample","Barcode","Tissue","condition","post.surgery")){
    
    if(! ( all( shared_colData %in% names(colData(insce)) ) )){
        stop("Check the colData columns you've indicated. They don't all seem to be present.")
    }
    
    outsce <- insce
    colData(outsce) <- colData(outsce)[, shared_colData]
    logcounts(outsce) <- NULL
    if("UMAP" %in% reducedDimNames(outsce)){
        reducedDim(outsce, paste0("UMAP_", pf))<- reducedDim(outsce, "UMAP")
        reducedDim(outsce, "UMAP") <- NULL
    }
    if("PCA_corr" %in% reducedDimNames(outsce)){
        reducedDim(outsce, paste0("PCA_corr_", pf)) <- reducedDim(outsce, "PCA_corr")
        reducedDim(outsce, "PCA_corr") <- NULL
    }
    rowData(outsce)[is.na(rowData(outsce)$ID),]$ID <- rowData(outsce)[is.na(rowData(outsce)$ID),]$Symbol
    # rownames(outsce) <- scater::uniquifyFeatureNames(rowData(outsce)$ID, rowData(outsce)$Symbol)
    rownames(outsce) <- rowData(outsce)$ID
    return(outsce)
}
```


```{r fig.width = 7.472222, fig.height = 5.5,   eval=T, context="data",results="asis", fig.align="center"}
lapply(names(scel), function(x){ 
  cat("\n\n##",x, " \n\n")
  
  sce = scel[[x]]
  
  shared_colData = colnames(colData(sce)) 
  list_of_sce <- lapply(unique(sce$Sample), function(x) individualize_samples(sce[, sce$Sample == x], pf = "allUnInteg",  shared_colData = shared_colData))
  
  
  universe <- Reduce(intersect, lapply(list_of_sce, rownames))
  list_of_sce2 <- lapply(list_of_sce, "[", i=universe)
  # generate logcounts
  # multiBatchNorm = Perform scaling normalization within each batch to provide comparable results to the lowest-coverage batch.
  normed.sce <- do.call(multiBatchNorm, list_of_sce2) # returns a list
  # Identifying a set of HVGs using stats from all batches, using logcounts
  all.dec <- lapply(normed.sce, modelGeneVar)
  combined.dec <- do.call(combineVar, all.dec)
  combined.hvg <- getTopHVGs(combined.dec, n=2000) 
  
  # Merge with MNN ----------------------------
  ## prep
  ## noCorrect = Provides a no-correction method that has the same interface as the correction functions. This allows users to easily swap function calls to examine the effect of correction.
  combined <- noCorrect(normed.sce)
  assayNames(combined) <- "logcounts"
  combined$Sample <- combined$batch
  set.seed(1010100)
  ## progressively merge cells from each sample in each batch until all cells 
  ## are mapped onto a common coordinate space
  print("Performing MNN")
  ## fastMNN = Correct for batch effects in single-cell expression data using a fast version of the mutual nearest neighbors (MNN) method.
  multiout <- fastMNN(combined, batch=combined$Sample, subset.row=combined.hvg)
  # Renaming metadata fields for easier communication later.
  multiout$Sample <- multiout$batch
  ## UMAP-----------------------------------
  print("Performing UMAP")
  set.seed(10101010)
  multiout <- runUMAP(multiout, dimred="corrected")
  
  # saveRDS(multiout,file = paste0(fn, "_MNNmerged.rds"))
  
  cluster_ks = c(20,50,100,150,200,300)
  
  ## CLUSTERING -----------------------------
  print(paste0("Performing clustering for ", paste("k =", cluster_ks, collapse = ", " )))
  for(i in cluster_ks){
    g <- buildSNNGraph(multiout, use.dimred="corrected", k = i)
    clusters <- igraph::cluster_louvain(g)
    multiout[[paste0("cluster_k",i)]] <- factor(clusters$membership)
  }
  
  ## combine
  universe <- Reduce(intersect, lapply(list_of_sce, rownames))
  list_of_sce <- lapply(list_of_sce, "[", i=universe)
  comb.mat <- lapply(list_of_sce, counts) %>% do.call(cbind, .)
  
  ## colData 
  cd <- lapply(list_of_sce, function(x) colData(x)[, shared_colData]) %>% do.call(rbind, .)
  
  ## add clusters from multiout to combined SCE 
  cd2 <- as.data.frame(colData(multiout))
  cd2$Cell <- rownames(cd2)
  cd2 <- cd2[, c("Cell",grep("cluster_k", names(cd2), value=TRUE))]
  newcd <- merge(cd, cd2, by = "Cell") 
  rownames(newcd) <- newcd$Cell
  newcd <- newcd[colnames(comb.mat),]
  
  ### rowData
  rd <- rowData(list_of_sce[[1]])[, c("ID","Symbol")]
  rd <- rd[rownames(comb.mat),]
  
  out.sce <- SingleCellExperiment(
    assays = list(counts = comb.mat),
    colData = newcd, rowData = rd)
  
  ## add redDims from the merged data set
  rdu <- reducedDim(multiout, "UMAP") 
  reducedDim(out.sce, "UMAP") <- rdu[colnames(out.sce),]
  reducedDim(out.sce, "PCA_corr") <- reducedDim(multiout, "corrected")
  
  ## add log-counts
  qckclst <- quickCluster(out.sce, method = "igraph", min.mean = 0.1)
  out.sce <- computeSumFactors(out.sce, min.mean=0.1, cluster = qckclst)
  out.sce <- scater::logNormCounts(out.sce)

  rownames(out.sce) <- scater::uniquifyFeatureNames(rowData(out.sce)$ID, rowData(out.sce)$Symbol)
  saveRDS(out.sce, file = paste0("sce_TISCH_filtered_not_annotated_sampleIntegration_", x,"_2022-07-26.rds"))
}) %>% invisible()
```


# Session Info
```{r session, message=FALSE, warning=FALSE, cache=FALSE,echo=FALSE, fig.width=10, fig.height=5.5, context="data"}
sessionInfo()
```

